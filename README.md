
# Applied Data Science Lab (WQU) 🧪📊

Welcome to my **Applied Data Science Lab** repository! This repository showcases my learning journey and projects completed as part of the **WorldQuant University (WQU)** Applied Data Science Lab program.

---

## 📝 **Course Overview**

The Applied Data Science Lab is a hands-on program designed to strengthen data analysis, visualization, and modeling skills using real-world datasets. It covers essential data science techniques, tools, and methodologies applied across various domains.

---

## 📚 **Topics Covered**

### **1. Data Wrangling**
- Importing, cleaning, and transforming datasets for analysis.
- Working with different file formats (CSV, JSON, gzip, etc.).
- Handling missing values and outliers effectively.

### **2. Exploratory Data Analysis (EDA)**
- Descriptive statistics and data visualization techniques.
- Identifying patterns, trends, and insights from data.
- Using libraries like Pandas, Matplotlib, and Seaborn.

### **3. Feature Engineering**
- Selecting and transforming features to improve model performance.
- Encoding categorical variables, scaling numerical features, and creating new derived features.

### **4. Supervised Learning**
- Implementing machine learning models such as:
  - Linear Regression
  - Logistic Regression
  - Decision Trees
  - Support Vector Machines (SVM)
- Evaluating models with metrics like RMSE, accuracy, precision, and recall.

### **5. Ensemble Models**
- Building advanced models using:
  - Random Forest
  - Gradient Boosting (XGBoost, LightGBM)
- Understanding feature importance and hyperparameter tuning.

### **6. Unsupervised Learning**
- Exploring clustering methods like K-Means and hierarchical clustering.
- Dimensionality reduction techniques such as PCA.

### **7. Data Ethics and Bias**
- Understanding ethical implications of data science.
- Identifying and mitigating bias in datasets and models.

---

## 🚀 **Projects and Assignments**

Each project involved real-world datasets, where I:
1. **Wrangled data** for cleanliness and usability.
2. Conducted **Exploratory Data Analysis (EDA)** to discover insights.
3. Built **predictive models** to solve domain-specific challenges.
4. Evaluated and **optimized models** for performance and generalization.

Examples include:
- Predicting property prices based on real estate data.
- Bankruptcy prediction using financial metrics.
- Analyzing trends in customer support queries.

---

## 🛠️ **Tools and Libraries**
- **Programming Language:** Python
- **Libraries:** Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, XGBoost, LightGBM
- **Version Control:** Git & GitHub
- **Platforms:** Jupyter Notebooks, Colab

---

## 🌟 **What I Gained**
- A deeper understanding of the end-to-end data science pipeline.
- Practical experience with real-world datasets and machine learning models.
- Improved problem-solving and critical-thinking skills.

---

## 📂 **Structure of the Repository**
```plaintext
.
├── data/           # Sample datasets used in the projects
├── notebooks/      # Jupyter Notebooks for each module
├── models/         # Saved model files and outputs
├── requirements.txt# Required Python dependencies
└── README.md       # This file
